#!/usr/bin/env python

# Purpose:  manage demo clusters

import os
import datetime
import functools
import collections
import sys
import shutil
import subprocess
import time
import argparse
import boto3
import concurrent.futures
import re

# from https://stackoverflow.com/questions/2331592/why-does-datetime-datetime-utcnow-not-contain-timezone-information

# What kind of idiot 'standard library' can't even natively represent
# UTC when it requires you to deal with timezones to compare dates?

ZERO = datetime.timedelta(0)
class UTC(datetime.tzinfo):
    """UTC"""

    def utcoffset(self, dt):
        return ZERO

    def tzname(self, dt):
        return "UTC"

    def dst(self, dt):
        return ZERO

utc = UTC()

def cache(f):
    '''Cache the funciton call arguments'''
    cache=dict()
    @functools.wraps(f)
    def wrapper(*args):
        if not isinstance(args, collections.Hashable):
            return f(*args)
        if args in cache:
            return cache[args]
        else:
            result = f(*args)
            cache[args]=result
            return result

    return wrapper

def list_clusters(session, args):
    '''main 'list' command implementation.  

Select clusters using common 'select' method and print them out'''

    print_stack_info(session, args, select(session, args))
    return True

def print_stack_info(session, args, stacks):
    ''' Given a list of stacks from cloudformation, print the info for each stack'''
    cf = session.resource('cloudformation')

    for x in stacks:
        url=[""]
        if x['StackStatus'] == 'CREATE_COMPLETE':
            stack = cf.Stack(x['StackName'])
        else:
            stack=None
        if stack:
            # done this way because https://hynek.me/articles/hasattr/
            try:
                outputs = stack.outputs
                if outputs:
                    url = [y['OutputValue'] 
                           for y in outputs
                           if y['OutputKey'] == args.url_property]
            except AttributeError:
                pass

        if len(url)<1:
            url=[""]

        print "{} {} {} ".format(x['StackName'], x['StackStatus'], url[0])

def select(session, args):
    '''Common cluster selection method.

This should be used by any function selecting clusters to implement --include and --exclude consistently'''

    cf = session.client("cloudformation")

    result = cf.list_stacks(
    StackStatusFilter=[
        'CREATE_IN_PROGRESS','CREATE_FAILED','CREATE_COMPLETE','ROLLBACK_IN_PROGRESS','ROLLBACK_FAILED','ROLLBACK_COMPLETE','DELETE_IN_PROGRESS','DELETE_FAILED','UPDATE_IN_PROGRESS','UPDATE_COMPLETE_CLEANUP_IN_PROGRESS','UPDATE_COMPLETE','UPDATE_ROLLBACK_IN_PROGRESS','UPDATE_ROLLBACK_FAILED','UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS','UPDATE_ROLLBACK_COMPLETE','REVIEW_IN_PROGRESS',
    ])

    stacks = result['StackSummaries']

    if not args.no_filter_names:
        stacks = [x for x in stacks if re.match("^.*\\d+-\\d+$", x['StackName'])]

    if args.all:
        pass
    elif not args.include and not args.exclude:
        filter = os.environ['USER']
        stacks = [x for x in stacks if filter in x['StackName']]

    if args.status:
        stacks = [x for x in stacks if args.status in x['StackStatus']]

    if args.include:
        filter = args.include[0]
        stacks = [x for x in stacks if filter in x['StackName']]

    if args.exclude:
        filter = args.exclude[0]
        stacks = [x for x in stacks if not filter in x['StackName']]

    if args.expired:
        now = datetime.datetime.now(utc)
        stacks = [x for x in stacks if is_stack_expired(cf, x, now)]

    if args.failed:
        stacks = [x for x in stacks if 'FAILED' in x['StackStatus']]

    return stacks

def is_stack_expired(cf, stack, now):
    '''If the stack has a DeleteAfter and that time has passed, return True'''

    ret  = cf.describe_stacks(StackName=stack['StackName'])

    try:
        details = ret['Stacks'][0] 
        tag = [x['Value'] for x in details['Tags'] if x['Key'] == "DeleteAfter"]
        if tag:
            delete_after = tag[0]
            match = re.search("(\\d+)h", delete_after, flags=re.IGNORECASE)
            if not match:
                return False

#            print "delay is {}".format(delete_after)

            delta = datetime.timedelta(hours=int(match.group(1)))
            created = details['CreationTime']
            end = created + delta
#            print "Created on {} with expriation {}".format(created, delta)
#            print "Now is {}".format(now)
#            print "Expires at {}".format(end)

            if now > end:
                return True
    except Exception as e:
        print "Exception! {}".format(e)
        # Ignore any errors in looking up tags
        pass

    return False

def delete_clusters(session, args):
    '''main 'delete' command

Select the clusters and then delete them in parallel.'''
    stacks = select(session, args)
    futures=[]

    s3 = session.resource('s3')
    params = read_params(args.params_file)

    bucket_name = params['Bucket']


    with  concurrent.futures.ThreadPoolExecutor(args.parallel) as pool:
        for stack in stacks:
            f = pool.submit(delete_cluster, stack, session, args)
            f.add_done_callback(lambda x: delete_s3(bucket_name, stack['StackName'], s3))
            futures.append(f)
        
    return reduce(lambda x,y: x and y, map(lambda x: x.done(), futures), True)

def delete_s3(bucket_name, name, s3):
    '''Delete the stack creation resources from s3'''
    print "Deleting files in s3://{}/templates/{}".format(bucket_name, name)
    prefix = "templates/{}".format(name)

    bucket = s3.Bucket(bucket_name)
    r = bucket.objects.filter(Prefix=prefix).delete()

    if r == []:
        return True

    code = r[0]['ResponseMetadata']['HTTPStatusCode']
    success = code >= 200 and code < 300

    if success:
        return True
    else:
        print "...deletion of files in {}/{} FAILED".format(bucket_name, name)
        return False
    

def find_ecs_cluster(ecs, stack_name):
    '''Find the ECS cluster with the given name'''
    cluster = ecs.describe_clusters(clusters=[stack_name])
    return cluster['clusters'][0]

def delete_ecs_cluster(ecs, stack_name, p):
    '''Delete the given ECS cluster.

Arguments:
  ecs -- the boto3 ecs client
  stack_name -- the name of the ecs cluster
  p -- a function of one argument that will be called with status update strings
'''
    services=[]
    response = {'nextToken': 'True'}

    # Get all the services in multiple calls, because boto only
    # returns 10 at a time.

    while 'nextToken' in response:
        response = ecs.list_services(cluster=stack_name)
        services.extend(response['serviceArns'])

    p("downscaling services")
    for arn in services:
        ecs.update_service(cluster=stack_name,
                           service=arn,
                           desiredCount=0)

    waiter = ecs.get_waiter('services_inactive')

    # this idiocy is required by boto, which was clearly written with
    # a GUI in mind
#    chunks = [services[i:i + 10] for i in xrange(0, len(services), 10)]
#    map(lambda chunk: waiter.wait(cluster=stack_name, services=chunk), chunks)

    # At this point all services are inactive, so we can delete them.
    p("deleting services")
    for arn in services:
        ecs.delete_service(cluster=stack_name, service=arn)

    # now that all the services are deleted, we can delete the cluster
    p("deleting ecs cluster")
    ecs.delete_cluster(cluster=stack_name)

def delete_cluster(stack, session, args):
    '''Delete a single cluster given the stack object'''
    cf = session.client('cloudformation')

    stack_name=stack['StackName']

    print "Deleting cluster %s" % stack_name

    def p(message):
        print "...{}: {}".format(stack_name, message)

    p("deleting stack")

    cf.delete_stack(StackName=stack_name)

    waiter = cf.get_waiter('stack_delete_complete')
    try:
        waiter.wait(StackName=stack_name)
        p("SUCCESS deleting stack")
        print "SUCCESS deleting cluster %s" % stack_name
        return
    except:
        pass

    p("deletion blocked by undeleted resources")
    # manually delete the cluster
    ecs=session.client('ecs')
    cluster = find_ecs_cluster(ecs, stack_name)

    # Perform the delete
    if cluster:
        p("deleting ECS cluster")
        delete_ecs_cluster(ecs, stack_name, p)
    else:
        p("ECS cluster already deleted")

    # Now we'll have to delete the stack again

    p("deleting stack")
    cf.delete_stack(StackName=stack_name)
    try:
        waiter.wait(StackName=stack_name)
        print "SUCCESS deleting %s" % stack_name
        return True
    except:
        print "FAILED to delete cluster %s" % stack_name
        return False


@cache
def sync_to_s3(session, aws_region, bucket_name, name):
    print "Copying resources to //s3/{}/templates/{}".format(bucket_name, name)
    target_dir = os.path.dirname(__file__) + "/../cfn/"

    s3 = session.resource('s3')

    for filename in os.listdir(target_dir):
        try:
            obj = s3.Object(bucket_name, "templates/" + name + "/" + filename)
            obj.put(Body=open(os.path.join(target_dir, filename), 'rb'))
        except Exception as e:
            print "FAILED to sync {} to {}".format(filename, bucket_name)
            raise e

    target_dir = os.path.dirname(__file__) + "/../configScripts/"

    for filename in os.listdir(target_dir):
        try:
            obj = s3.Object(bucket_name, "templates/" + name + "/scripts/" + filename)
            obj.put(Body=open(os.path.join(target_dir, filename), 'rb'))
        except Exception as e:
            print "FAILED to sync {} to {}".format(filename, bucket_name)
            raise e


    #ship tar file to s3
    syncComand = "aws s3 sync " + os.path.dirname(__file__) + "/../ansible s3://" + bucket_name + "/templates/" + name + "/ansible/"
    subprocess.Popen(syncComand, shell=True)

def create_cluster_name(number, args):
    '''Create a cluster name from the number on which we're working and the given command line args'''
    if args.suffix:
        return "{}-{}-{}".format(args.prefix, args.user, args.suffix)
    else:
        return "{}-{}-{}".format(args.prefix, args.user, time.strftime("%Y%m%d-%H%M-{}".format(number)))

def create_clusters(session, args):
    '''main 'create' command

Create one or more clusters as requested
'''
    pool = concurrent.futures.ThreadPoolExecutor(args.parallel)
    cf = session.client("cloudformation")
    cfr = session.resource("cloudformation")

    names = map(lambda number: create_cluster_name(number, args), range(1, args.count+1))

    for name in names:
        create_cluster(name, session, args)

    statuses = pool.map(lambda name: wait_for_stack(name, cf, cfr, args), names)

    bye = True
    for i, result in enumerate(statuses):
        print "Waiting for {} returned {}".format(names[i], result)
        bye = bye and result

    return bye

@cache
def read_params(file):
    '''Read a parameters file and return an array of parameters
    suitable to passing to
    boto3.client('cloudformation').create_stack'''

    if not os.path.exists(file):
        other = os.path.dirname(__file__) + "/../" + params_file
        if os.path.exists(other):
            file = other

    linepattern = re.compile("(\w+)\s*[:=]\s*(\S+)\s*")

    params = { x[0]: x[1] for x in map(
            lambda x: (x.group(1),
                       x.group(2)),
            filter(None, map(linepattern.match,
                             open(file))))}

    return params


@cache
def get_template_body(template):
    '''Return the entire template body as a string'''
    if not os.path.exists(template):
        other  = os.path.dirname(__file__) + "/../" + template
        if os.path.exists(other):
            template=other
    with open(template) as f:
        return f.read()



def format_params(params):
    '''Pretty print params so that they line up nicely'''
    width = reduce(max, map(len, params))

    return ["{0: <{width}} = {1}".format(x, y, width=width) for x,y in params.items()]


def create_cluster(name, session, args):
    '''Create a single cluster of the given name.  

This function does *NOT* wait for cluster build to complete, only for
the command to return successfully.
'''
    print "Creating cluster %s" % name
    # TODO:  make this file relative to the script path

    # Turn the parameters file into a dict with name=value
    params = read_params(args.params_file)

    # Override the parameters we need to
    params['EcsClusterName'] = name
    if args.key_name is not None:
        params['KeyName'] = args.key_name

    # Now turn our dict into an array suitable for passing to create_stack
    paramArgs = [dict(ParameterKey=x, ParameterValue=y) for x,y in params.items()]

    template = get_template_body(args.template)

    tags = [
        dict(Key='Owner',
             Value=os.environ['USER'])
        ]

    # Upload cfn templates to s3 bucket
    aws_region = params['BucketRegion']
    bucket_name = params['Bucket']

    if args.delete_after:
        tags.append(dict(Key='DeleteAfter',
                         Value=args.delete_after + "h"))

    cfn = session.client("cloudformation")

    if(args.dry_run):
        print "DRY RUN:  create stack {} with\n   {}".format(
            name,
            "\n   ".join(format_params(params)))
    else:
        sync_to_s3(session, aws_region, bucket_name, name)
        cfn.create_stack(
            StackName = name,
            TemplateBody = template,
            Parameters = paramArgs,
            DisableRollback = True,
            Tags=tags,
            Capabilities=['CAPABILITY_IAM']
            )


def wait_for_stack(name, client, resource, args):
    '''Wait for the cloudformation stack with the given name to complete

Arguments:
name - name of the stack
client -- boto3 cloudformation client
resource -- boto3 cloudformation resource
args -- command line arguments
'''

    if args.no_wait:
        print "not waiting on %s" % name
        return True

    print "...waiting for %s to create" % name
    waiter = client.get_waiter("stack_create_complete")
    try:
        waiter.wait(StackName=name)

        stack = resource.Stack(name)
        print "{}: SUCCESS".format(name)

        for y in stack.outputs:
            print(y['OutputKey'], y['OutputValue'])
        return True

    except (boto3.ClientError, boto3.WaiterError) as ex:
        template = "ERROR: Cloud Formation stack (%s) creation FAILED. An exception of type {0} occurred. Arguments:\n{1!r}"
        message = template.format(name, type(ex).__name__, ex.args)
        print message
        return False


def main():
    '''The main event!'''
    parser = argparse.ArgumentParser(description="Manage Demo Clusters")

    parser.add_argument("--debug", help="Enables debug output", default=False)
    parser.add_argument("--profile", help="The AWS profile to use", )
    parser.add_argument("--parallel", help="Number of operations to perform in parallel", default=40)
    parser.add_argument("--url-property", help="Name of the StorefrontURL CloudFormation export property", default="StorefrontElbURL")

    selectParser = argparse.ArgumentParser(add_help=False)

    selectParser.add_argument("--all", help="include all stacks", action='store_true', default=False)
    selectParser.add_argument("--include", help="include clusters containing", nargs=1)
    selectParser.add_argument("--exclude", help="exclude clusters containing", nargs=1)
    selectParser.add_argument("--expired", help="include only expired stacks", action='store_true', default=False)
    selectParser.add_argument("--failed", help="include only stacks with failed operations", action='store_true', default=False)
    selectParser.add_argument("--status", help="include only stacks with the given word in the status")
    selectParser.add_argument("--no-filter-names", help="Do not filter the stacks by the conventional naming pattern", action='store_true')

    fileChoiceParser = argparse.ArgumentParser(add_help=False)
    fileChoiceParser.add_argument("--params-file", help="Parameters file", default="params/demo.params")
    fileChoiceParser.add_argument("--template", help="CFN Template file", default="cfn/demo.cfn.json")

    subs = parser.add_subparsers(help='sub-command help')

    parse_create = subs.add_parser('create', help='Create one or more clusters', parents=[fileChoiceParser])
    parse_create.set_defaults(function=create_clusters)

    parse_list = subs.add_parser('list', help='List clusters', parents=[selectParser])
    parse_list.set_defaults(function=list_clusters)

    parse_delete = subs.add_parser('delete', help='Delete clusters', parents=[selectParser, fileChoiceParser])
    parse_delete.set_defaults(function=delete_clusters)

    def check_delete_after (x):
        if x.endswith('h'):
            return x
        else:
            raise argparse.ArgumentTypeError("--delete-after must end in 'h'")

    parse_create.add_argument("--user", help="user name to include in cluster name", default=os.environ['USER'])
    parse_create.add_argument("--prefix", help="cluster name prefix", default='interactive-demo')
    parse_create.add_argument("--no-wait", help="Do not wait for cluster completion", action='store_true')
    parse_create.add_argument("--dry-run", help="Do not actually create the stack", action='store_true')
    parse_create.add_argument("--delete-after", help="Hours until the cluster should be deleted", type=check_delete_after)

    group = parse_create.add_mutually_exclusive_group()
    group.add_argument("--count", help="number of clusters to create", type=int,  default=1)
    group.add_argument("--suffix", help="cluster name suffix.  Default is a timestamp")
    group.add_argument("--key-name", help="SSH key name for instance", default=None)

    args = parser.parse_args()

    level = boto3.logging.INFO
    if args.debug:
        level = boto3.logging.DEBUG
    boto3.set_stream_logger('boto3', level=level)
    boto3.set_stream_logger('botocore', level=level)
    boto3.set_stream_logger('boto3.resources', level=level)

    if args.profile:
        session = boto3.Session(profile_name=args.profile)
    else:
        session = boto3.Session()

    if args.function(session, args):
        print("SUCCESS: Deployed cluster %s" % args.function)
        sys.exit(0)
    else:
        print("ERROR: Failed to deploy the cluster @ running %s" % args.function)
        sys.exit(1)

if __name__ == "__main__":
    main()
